#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CIF Enrichment - Metadata Matching
===================================
√ñsszehasonl√≠tja a 8,390 CIF-et a metadata f√°jlok COD FISCAL-jaival.
Kinyeri: c√©gn√©v, struktur√°lt c√≠m, kontakt info, jogi adatok.
"""

import json
import pandas as pd
import re
from pathlib import Path
from collections import defaultdict

class CIFEnricher:
    """CIF adatok b≈ëv√≠t√©se metadata f√°jlokb√≥l"""

    def __init__(self, base_path='.'):
        self.base_path = Path(base_path)
        self.bilanturi_cifs = set()
        self.metadata_files = []
        self.colectare_file = 'colectare deseuri punct ro DUMP 2023.xlsx'

        self.enriched_data = {}
        self.stats = defaultdict(int)

        print("=" * 80)
        print("CIF ENRICHMENT - METADATA MATCHING")
        print("=" * 80)

    def normalize_cif(self, cif_value):
        """CIF normaliz√°l√°s - FIXED: float ‚Üí int ‚Üí str (nem extra 0-k!)"""
        if pd.isna(cif_value):
            return None
        try:
            # HELYES: 29036053.0 ‚Üí 29036053 (NEM 290360530!)
            return str(int(float(cif_value)))
        except:
            return None

    def parse_address(self, address):
        """C√≠m struktur√°l√°sa: megye, v√°ros, utca+sz√°m"""
        if pd.isna(address) or not address:
            return {'judet': None, 'oras': None, 'strada': None}

        address = str(address).strip()

        # Megye (Jud. vagy jude»õ)
        judet = None
        judet_match = re.search(r'Jud\.?\s+([A-ZƒÇ√Ç√é»ò»ö][A-ZƒÇ√Ç√é»ò»öa-zƒÉ√¢√Æ»ô»õ\s]+)', address, re.IGNORECASE)
        if judet_match:
            judet = judet_match.group(1).strip()

        # V√°ros/Localitate
        oras = None
        # Keres√ºnk "ORA»ò, Jud." vagy "Nr. X, ORA»ò" mint√°t
        oras_patterns = [
            r',\s*([A-ZƒÇ√Ç√é»ò»ö][A-ZƒÇ√Ç√é»ò»öa-zƒÉ√¢√Æ»ô»õ\s]+),\s*(?:Cod\s*Postal|Jud\.)',
            r'(?:STR\.|BD\.|CAL\.)\s+[^,]+,\s*([A-ZƒÇ√Ç√é»ò»ö][A-ZƒÇ√Ç√é»ò»öa-zƒÉ√¢√Æ»ô»õ\s]+),',
            r'Nr\.\s*\d+[^,]*,\s*([A-ZƒÇ√Ç√é»ò»ö][A-ZƒÇ√Ç√é»ò»öa-zƒÉ√¢√Æ»ô»õ\s]+)',
        ]

        for pattern in oras_patterns:
            match = re.search(pattern, address, re.IGNORECASE)
            if match:
                oras = match.group(1).strip()
                break

        # Ha nincs v√°ros, pr√≥b√°ljuk meg a Jud. el≈ëtti r√©szt
        if not oras and judet:
            before_jud = address.split('Jud.')[0].strip()
            parts = before_jud.split(',')
            if len(parts) >= 2:
                oras = parts[-1].strip()

        # Utca + sz√°m
        strada = None
        strada_match = re.search(r'((?:STR\.|BD\.|CAL\.|STRADA|BULEVARDUL)\s+[^,]+(?:,\s*Nr\.\s*\d+[^,]*)?)', address, re.IGNORECASE)
        if strada_match:
            strada = strada_match.group(1).strip()
        else:
            # Ha nincs STR/BD/CAL prefix, keres√ºnk "Nr. X" mint√°t
            nr_match = re.search(r'(Nr\.\s*\d+[^,]*)', address, re.IGNORECASE)
            if nr_match:
                strada = nr_match.group(1).strip()

        return {
            'judet': judet,
            'oras': oras,
            'strada': strada
        }

    def extract_phones(self, phone_str):
        """Telefonsz√°mok kinyer√©se (t√∂bb is lehet)"""
        if pd.isna(phone_str) or not phone_str:
            return []

        phone_str = str(phone_str)
        # Keres√ºnk telefonsz√°m mint√°kat
        phones = re.findall(r'0\d{3}[-\s]?\d{3}[-\s]?\d{3}', phone_str)
        return list(set(phones))

    def extract_emails(self, email_str):
        """Email-ek kinyer√©se (t√∂bb is lehet)"""
        if pd.isna(email_str) or not email_str:
            return []

        email_str = str(email_str)
        emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', email_str)
        return list(set(emails))

    def load_bilanturi_cifs(self):
        """8,390 CIF bet√∂lt√©se"""
        print("\n[1/6] Bilanturi CIF-ek bet√∂lt√©se...")

        try:
            with open(self.base_path / 'bilanturi_integrated.json', 'r', encoding='utf-8') as f:
                data = json.load(f)

            for company in data:
                cif = company.get('CIF')
                if cif:
                    self.bilanturi_cifs.add(cif)
                    # Inicializ√°ljuk az enriched adatot
                    self.enriched_data[cif] = {
                        'cif': cif,
                        'company_names': set(),
                        'addresses': [],
                        'phones': set(),
                        'emails': set(),
                        'j_numbers': set(),
                        'cod_caen': set(),
                        'capital_subscris': set(),
                        'coordinates': set(),
                        'sources': set()
                    }

            print(f"  ‚úì {len(self.bilanturi_cifs):,} CIF bet√∂ltve")

        except Exception as e:
            print(f"  ‚ùå HIBA: {e}")

    def identify_metadata_files(self):
        """Metadata f√°jlok azonos√≠t√°sa"""
        print("\n[2/6] Metadata f√°jlok azonos√≠t√°sa...")

        candidates = [
            'metale.xlsx', 'neferoase.xlsx', 'aluminiu.xlsx',
            'q_inox.xlsx', 'q_importator_profile_aluminiu.xlsx',
            '2442.xlsx', '2443.xlsx', '2444.xlsx', '2445.xlsx',
            '3811.xlsx', '3812.xlsx', '3821.xlsx', '3831.xlsx', '3832.xlsx',
            '4677.xlsx'
        ]

        for file in candidates:
            if (self.base_path / file).exists():
                self.metadata_files.append(file)
                print(f"  ‚úì {file}")

        print(f"\n  √ñsszesen: {len(self.metadata_files)} metadata f√°jl")

    def process_metadata_files(self):
        """Metadata f√°jlok feldolgoz√°sa"""
        print("\n[3/6] Metadata f√°jlok feldolgoz√°sa...")

        for file in self.metadata_files:
            print(f"\n  Feldolgoz√°s: {file}...")

            try:
                df = pd.read_excel(self.base_path / file)

                if 'COD FISCAL' not in df.columns:
                    print(f"    ‚ö† Nincs COD FISCAL oszlop, skip")
                    continue

                df['CIF_normalized'] = df['COD FISCAL'].apply(self.normalize_cif)

                matches = 0
                for idx, row in df.iterrows():
                    cif = row['CIF_normalized']

                    if not cif or cif not in self.bilanturi_cifs:
                        continue

                    matches += 1
                    enriched = self.enriched_data[cif]

                    # Company name
                    if pd.notna(row.get('Company Name')):
                        enriched['company_names'].add(str(row['Company Name']).strip())

                    # Address (struktur√°lt)
                    if pd.notna(row.get('Full Address')):
                        address_str = str(row['Full Address'])
                        parsed = self.parse_address(address_str)
                        enriched['addresses'].append({
                            'full': address_str,
                            'parsed': parsed
                        })

                    # Phones
                    if pd.notna(row.get('Phone Number')):
                        phones = self.extract_phones(str(row['Phone Number']))
                        enriched['phones'].update(phones)

                    # Emails
                    if pd.notna(row.get('Email')):
                        emails = self.extract_emails(str(row['Email']))
                        enriched['emails'].update(emails)

                    # J number (NUMƒÇR DE √éNREGISTRARE)
                    if pd.notna(row.get('NUMƒÇR DE √éNREGISTRARE')):
                        enriched['j_numbers'].add(str(row['NUMƒÇR DE √éNREGISTRARE']).strip())

                    # COD CAEN
                    if pd.notna(row.get('COD CAEN')):
                        enriched['cod_caen'].add(str(row['COD CAEN']).strip())

                    # Capital Subscris
                    if pd.notna(row.get('CAPITALUL SUBSCRIS')):
                        enriched['capital_subscris'].add(str(row['CAPITALUL SUBSCRIS']).strip())

                    # Coordinates
                    if pd.notna(row.get('Co-ordinates')):
                        enriched['coordinates'].add(str(row['Co-ordinates']).strip())

                    # Source
                    enriched['sources'].add(file)

                print(f"    ‚úì {matches} CIF match tal√°lva")
                self.stats[f'matches_{file}'] = matches

            except Exception as e:
                print(f"    ‚ùå HIBA: {e}")

    def process_colectare_dump(self):
        """Colectare dump feldolgoz√°sa"""
        print("\n[4/6] Colectare dump feldolgoz√°sa...")

        try:
            df = pd.read_excel(self.base_path / self.colectare_file)

            # Colectare-ben nincs COD FISCAL, de van Company Name
            # Ezt company name alapj√°n pr√≥b√°ljuk match-elni

            print(f"  ‚ö† Colectare dump-ban nincs COD FISCAL")
            print(f"  ‚Üí C√©gn√©v alap√∫ matching k√©s≈ëbb implement√°lhat√≥")

            # TODO: Fuzzy matching by company name

        except Exception as e:
            print(f"  ‚ùå HIBA: {e}")

    def calculate_statistics(self):
        """Statisztik√°k sz√°m√≠t√°sa"""
        print("\n[5/6] Statisztik√°k sz√°m√≠t√°sa...")

        total_enriched = 0
        total_with_name = 0
        total_with_address = 0
        total_with_phone = 0
        total_with_email = 0
        total_with_j = 0
        total_with_caen = 0
        total_with_capital = 0
        total_with_coords = 0

        for cif, data in self.enriched_data.items():
            has_any = (
                len(data['company_names']) > 0 or
                len(data['addresses']) > 0 or
                len(data['phones']) > 0 or
                len(data['emails']) > 0 or
                len(data['j_numbers']) > 0 or
                len(data['cod_caen']) > 0 or
                len(data['capital_subscris']) > 0 or
                len(data['coordinates']) > 0
            )

            if has_any:
                total_enriched += 1

            if len(data['company_names']) > 0:
                total_with_name += 1
            if len(data['addresses']) > 0:
                total_with_address += 1
            if len(data['phones']) > 0:
                total_with_phone += 1
            if len(data['emails']) > 0:
                total_with_email += 1
            if len(data['j_numbers']) > 0:
                total_with_j += 1
            if len(data['cod_caen']) > 0:
                total_with_caen += 1
            if len(data['capital_subscris']) > 0:
                total_with_capital += 1
            if len(data['coordinates']) > 0:
                total_with_coords += 1

        self.stats['total_cifs'] = len(self.bilanturi_cifs)
        self.stats['enriched_cifs'] = total_enriched
        self.stats['with_company_name'] = total_with_name
        self.stats['with_address'] = total_with_address
        self.stats['with_phone'] = total_with_phone
        self.stats['with_email'] = total_with_email
        self.stats['with_j_number'] = total_with_j
        self.stats['with_cod_caen'] = total_with_caen
        self.stats['with_capital'] = total_with_capital
        self.stats['with_coordinates'] = total_with_coords

        print(f"\n  üìä STATISZTIK√ÅK:")
        print(f"  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        print(f"  √ñsszes CIF: {self.stats['total_cifs']:,}")
        print(f"  B≈ëv√≠tett CIF-ek: {total_enriched:,} ({100*total_enriched/self.stats['total_cifs']:.1f}%)")
        print(f"")
        print(f"  C√©gn√©vvel: {total_with_name:,} ({100*total_with_name/total_enriched:.1f}%)")
        print(f"  C√≠mmel: {total_with_address:,} ({100*total_with_address/total_enriched:.1f}%)")
        print(f"  Telefonnal: {total_with_phone:,} ({100*total_with_phone/total_enriched:.1f}%)")
        print(f"  Email-lel: {total_with_email:,} ({100*total_with_email/total_enriched:.1f}%)")
        print(f"  J sz√°mmal: {total_with_j:,} ({100*total_with_j/total_enriched:.1f}%)")
        print(f"  COD CAEN-nel: {total_with_caen:,} ({100*total_with_caen/total_enriched:.1f}%)")
        print(f"  T≈ëk√©vel: {total_with_capital:,} ({100*total_with_capital/total_enriched:.1f}%)")
        print(f"  Koordin√°t√°kkal: {total_with_coords:,} ({100*total_with_coords/total_enriched:.1f}%)")

    def export_enriched_data(self, output_file='cif_enriched.json'):
        """B≈ëv√≠tett adatok export√°l√°sa"""
        print(f"\n[6/6] Export ({output_file})...")

        # Set-eket list√°ra konvert√°l√°s
        export_data = []

        for cif, data in self.enriched_data.items():
            # Csak azok amiknek van legal√°bb egy √∫j adata
            if (len(data['company_names']) == 0 and
                len(data['addresses']) == 0 and
                len(data['phones']) == 0 and
                len(data['emails']) == 0 and
                len(data['j_numbers']) == 0 and
                len(data['cod_caen']) == 0 and
                len(data['capital_subscris']) == 0 and
                len(data['coordinates']) == 0):
                continue

            export_record = {
                'cif': cif,
                'company_names': list(data['company_names']),
                'addresses': data['addresses'],
                'phones': list(data['phones']),
                'emails': list(data['emails']),
                'j_numbers': list(data['j_numbers']),
                'cod_caen': list(data['cod_caen']),
                'capital_subscris': list(data['capital_subscris']),
                'coordinates': list(data['coordinates']),
                'sources': list(data['sources'])
            }

            export_data.append(export_record)

        # JSON ment√©s
        with open(self.base_path / output_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)

        file_size = (self.base_path / output_file).stat().st_size / 1024 / 1024
        print(f"  ‚úì Export√°lva: {len(export_data):,} b≈ëv√≠tett CIF, {file_size:.2f} MB")

        # Statisztik√°k is
        stats_file = output_file.replace('.json', '_stats.txt')
        with open(self.base_path / stats_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("CIF ENRICHMENT STATISTICS\n")
            f.write("=" * 80 + "\n\n")

            for key, value in sorted(self.stats.items()):
                f.write(f"{key}: {value:,}\n")

        print(f"  ‚úì Statisztik√°k: {stats_file}")

def main():
    """F≈ëprogram"""
    enricher = CIFEnricher()

    enricher.load_bilanturi_cifs()
    enricher.identify_metadata_files()
    enricher.process_metadata_files()
    enricher.process_colectare_dump()
    enricher.calculate_statistics()
    enricher.export_enriched_data('cif_enriched_fixed.json')  # FIXED VERSION!

    print("\n" + "=" * 80)
    print("‚úì CIF ENRICHMENT K√âSZ! (FIXED VERSION)")
    print("=" * 80)
    print("\nKimeneti f√°jlok:")
    print("  - cif_enriched_fixed.json")
    print("  - cif_enriched_fixed_stats.txt")

if __name__ == "__main__":
    main()
