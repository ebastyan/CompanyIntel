#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Colectare Dump Company Name Matching
=====================================
√ñsszehasonl√≠tja a colectare dump c√©gneveit a b≈ëv√≠tett CIF adatb√°zissal.
CSAK ELEMZ√âS - nem m√≥dos√≠t semmit!
"""

import json
import pandas as pd
import re
from difflib import SequenceMatcher

class ColectareNameMatcher:
    """C√©gn√©v matching a colectare dump √©s CIF enriched k√∂z√∂tt"""

    def __init__(self):
        self.cif_enriched = []
        self.colectare_dump = []

        self.cif_names = {}  # CIF -> normalized names
        self.colectare_names = []  # [(original, normalized), ...]

        self.exact_matches = []
        self.fuzzy_matches = []

        print("=" * 80)
        print("COLECTARE DUMP - C√âGN√âV MATCHING ELEMZ√âS")
        print("=" * 80)

    def normalize_company_name(self, name):
        """C√©gn√©v normaliz√°l√°s √∂sszehasonl√≠t√°shoz"""
        if pd.isna(name) or not name:
            return None

        name = str(name).strip().upper()

        # Form√°tumok standardiz√°l√°sa
        name = re.sub(r'\s+', ' ', name)  # T√∂bbsz√∂r√∂s space -> 1 space
        name = re.sub(r'\.', '', name)  # Pontok elt√°vol√≠t√°sa
        name = re.sub(r'S\s*R\s*L', 'SRL', name)  # S.R.L. / S R L -> SRL
        name = re.sub(r'S\s*A', 'SA', name)  # S.A. / S A -> SA
        name = re.sub(r'S\s*C\s*S', 'SCS', name)  # S.C.S -> SCS
        name = re.sub(r'S\s*C\s*A', 'SCA', name)  # S.C.A -> SCA
        name = re.sub(r'P\s*F\s*A', 'PFA', name)  # P.F.A -> PFA

        # Felesleges szavak elt√°vol√≠t√°sa
        name = name.replace('SOCIETATE COMERCIALA', '')
        name = name.replace('SOCIETATE', '')
        name = name.replace('COMERCIALA', '')
        name = name.replace('SC', '', 1)  # Els≈ë SC elt√°vol√≠t√°sa

        name = name.strip()

        return name if name else None

    def load_cif_enriched(self):
        """CIF enriched adatok bet√∂lt√©se"""
        print("\n[1/5] CIF enriched bet√∂lt√©se...")

        try:
            with open('cif_enriched.json', 'r', encoding='utf-8') as f:
                self.cif_enriched = json.load(f)

            # CIF -> c√©gnevek mapping
            for record in self.cif_enriched:
                cif = record['cif']
                names = record.get('company_names', [])

                normalized_names = set()
                for name in names:
                    normalized = self.normalize_company_name(name)
                    if normalized:
                        normalized_names.add(normalized)

                if normalized_names:
                    self.cif_names[cif] = {
                        'original': names,
                        'normalized': normalized_names
                    }

            print(f"  ‚úì {len(self.cif_enriched):,} CIF bet√∂ltve")
            print(f"  ‚úì {len(self.cif_names):,} CIF c√©gnevekkel")

        except Exception as e:
            print(f"  ‚ùå HIBA: {e}")

    def load_colectare_dump(self):
        """Colectare dump bet√∂lt√©se"""
        print("\n[2/5] Colectare dump bet√∂lt√©se...")

        try:
            df = pd.read_excel('colectare deseuri punct ro DUMP 2023.xlsx')

            print(f"  ‚úì {len(df):,} rekord bet√∂ltve")

            # C√©gnevek kinyer√©se √©s normaliz√°l√°sa
            for idx, row in df.iterrows():
                original_name = row.get('Company Name')

                if pd.notna(original_name):
                    normalized = self.normalize_company_name(original_name)

                    if normalized:
                        self.colectare_names.append({
                            'original': str(original_name).strip(),
                            'normalized': normalized
                        })

            print(f"  ‚úì {len(self.colectare_names):,} c√©gn√©v kinyerve")

        except Exception as e:
            print(f"  ‚ùå HIBA: {e}")

    def find_exact_matches(self):
        """Pontos egyez√©sek keres√©se"""
        print("\n[3/5] Pontos egyez√©sek keres√©se...")

        # CIF normalized names halmaz
        all_cif_normalized = set()
        for cif, data in self.cif_names.items():
            all_cif_normalized.update(data['normalized'])

        print(f"  CIF adatb√°zis egyedi c√©gnevek: {len(all_cif_normalized):,}")

        # Colectare normalized names halmaz
        colectare_normalized = set(c['normalized'] for c in self.colectare_names)
        print(f"  Colectare dump egyedi c√©gnevek: {len(colectare_normalized):,}")

        # Pontos egyez√©sek
        exact_match_names = all_cif_normalized.intersection(colectare_normalized)

        print(f"\n  üéØ PONTOS EGYEZ√âSEK: {len(exact_match_names):,} c√©gn√©v")

        # R√©szletes egyez√©sek
        for colectare_record in self.colectare_names:
            normalized = colectare_record['normalized']

            if normalized in exact_match_names:
                # Keres√©s melyik CIF-hez tartozik
                matching_cifs = []
                for cif, data in self.cif_names.items():
                    if normalized in data['normalized']:
                        matching_cifs.append(cif)

                self.exact_matches.append({
                    'colectare_name': colectare_record['original'],
                    'normalized': normalized,
                    'matching_cifs': matching_cifs,
                    'cif_count': len(matching_cifs)
                })

        print(f"  ‚úì {len(self.exact_matches):,} colectare rekord match-elt")

    def find_fuzzy_matches(self, threshold=0.85):
        """Fuzzy egyez√©sek keres√©se (hasonl√≥ nevek)"""
        print(f"\n[4/5] Fuzzy egyez√©sek keres√©se (threshold: {threshold})...")

        # Csak azok amik nem exact match
        exact_normalized = set(m['normalized'] for m in self.exact_matches)

        remaining_colectare = [
            c for c in self.colectare_names
            if c['normalized'] not in exact_normalized
        ]

        print(f"  Maradt colectare nevek: {len(remaining_colectare):,}")

        # CIF nevek list√°ja
        all_cif_normalized = []
        for cif, data in self.cif_names.items():
            all_cif_normalized.extend(data['normalized'])

        fuzzy_count = 0

        # Csak az els≈ë 1000-et n√©zem meg (gyorsas√°g miatt)
        sample_size = min(1000, len(remaining_colectare))

        print(f"  Minta: {sample_size} colectare n√©v vizsg√°lata...")

        for i, colectare_record in enumerate(remaining_colectare[:sample_size]):
            if i % 200 == 0:
                print(f"    Progress: {i}/{sample_size}...")

            colectare_norm = colectare_record['normalized']

            best_match = None
            best_ratio = 0

            for cif_norm in all_cif_normalized:
                ratio = SequenceMatcher(None, colectare_norm, cif_norm).ratio()

                if ratio > best_ratio and ratio >= threshold:
                    best_ratio = ratio
                    best_match = cif_norm

            if best_match:
                fuzzy_count += 1

                # Ha kev√©s tal√°lat, t√°roljuk
                if len(self.fuzzy_matches) < 100:
                    self.fuzzy_matches.append({
                        'colectare_name': colectare_record['original'],
                        'colectare_normalized': colectare_norm,
                        'matched_cif_name': best_match,
                        'similarity': best_ratio
                    })

        print(f"\n  üîç FUZZY EGYEZ√âSEK (mint√°ban): {fuzzy_count}/{sample_size} ({100*fuzzy_count/sample_size:.1f}%)")

    def generate_statistics(self):
        """Statisztik√°k gener√°l√°sa"""
        print("\n[5/5] Statisztik√°k gener√°l√°sa...")

        total_colectare = len(self.colectare_names)
        total_cif = len(self.cif_names)
        exact_matches = len(self.exact_matches)

        print(f"\n  üìä V√âGS≈ê STATISZTIK√ÅK:")
        print(f"  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        print(f"  CIF adatb√°zis (enriched): {total_cif:,} CIF")
        print(f"  Colectare dump: {total_colectare:,} c√©gn√©v")
        print(f"")
        print(f"  ‚úÖ PONTOS EGYEZ√âSEK: {exact_matches:,} ({100*exact_matches/total_colectare:.2f}%)")

        # T√∂bb CIF ugyanarra a n√©vre
        multiple_cif = sum(1 for m in self.exact_matches if m['cif_count'] > 1)
        print(f"  ‚ö† T√∂bb CIF ugyanarra a n√©vre: {multiple_cif:,}")

        # Top 10 egyez≈ë n√©v
        if self.exact_matches:
            print(f"\n  üèÜ TOP 10 EGYEZ≈ê C√âGN√âV:")
            for i, match in enumerate(self.exact_matches[:10], 1):
                print(f"    {i}. {match['colectare_name'][:60]}")
                print(f"       CIF-ek: {', '.join(match['matching_cifs'][:3])}")

        # Fuzzy p√©ld√°k
        if self.fuzzy_matches:
            print(f"\n  üîç FUZZY MATCH P√âLD√ÅK (hasonl√≥ nevek):")
            for i, match in enumerate(self.fuzzy_matches[:5], 1):
                print(f"    {i}. Colectare: {match['colectare_name'][:50]}")
                print(f"       CIF DB:     {match['matched_cif_name'][:50]}")
                print(f"       Hasonl√≥s√°g: {match['similarity']:.2%}")

        # Export
        output = {
            'total_colectare_names': total_colectare,
            'total_cif_enriched': total_cif,
            'exact_matches_count': exact_matches,
            'exact_matches_percentage': 100 * exact_matches / total_colectare,
            'exact_matches': self.exact_matches,
            'fuzzy_matches_sample': self.fuzzy_matches
        }

        with open('colectare_matching_results.json', 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        print(f"\n  ‚úì Eredm√©nyek export√°lva: colectare_matching_results.json")

def main():
    """F≈ëprogram"""
    matcher = ColectareNameMatcher()

    matcher.load_cif_enriched()
    matcher.load_colectare_dump()
    matcher.find_exact_matches()
    matcher.find_fuzzy_matches(threshold=0.85)
    matcher.generate_statistics()

    print("\n" + "=" * 80)
    print("‚úì ELEMZ√âS K√âSZ!")
    print("=" * 80)

if __name__ == "__main__":
    main()
